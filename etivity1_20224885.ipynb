{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "etivity1_20224885.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM2-ZAHecusI"
      },
      "source": [
        "Joseph Mc Laughlin, 20224885"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD0if9apY-E2"
      },
      "source": [
        "\n",
        "Task 1:\n",
        "\n",
        "Write a function in Python which takes a string as input and uses regular expressions to:\n",
        "\n",
        "(a) check if the given string is a valid Eircode or not; and \n",
        "\n",
        "(b) if the string is a valid Eircode, identify and print the Eircode's geographical district\n",
        "\n",
        "[3 marks]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRV0a_jpXT80",
        "outputId": "22d84ce6-500a-430f-9df3-2ab863a91dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "import re\n",
        "import csv\n",
        "\n",
        "!wget https://gist.githubusercontent.com/ajoorabchi/eac194a79dd26de8864f9206b7842ff1/raw/8ea1d8d5f74b5b2724e378b43d4df6094990c7db/Eircode%2520Routing%2520Key%2520Boundaries.csv\n",
        "filePath = \"/content/Eircode Routing Key Boundaries.csv\"\n",
        "\n",
        "with open(filePath, 'r') as f:\n",
        "  reader = csv.reader(f)\n",
        "  KeyRouteList = list(map(tuple, reader))\n",
        "  print(KeyRouteList)\n",
        "\n",
        "def eircodeValidator(eircode):\n",
        "  #Answer Here\n",
        "  x = re.search(\"^[ACDEFHKNPRTVWXY]{1}[0-9]{2}[\\ \\-]?[0-9ACDEFHKNPRTVWXY]{4}$\", eircode)\n",
        "                  #\"(?:^[AC-FHKNPRTV-Y][0-9]{2}|D6W)[ -]?[0-9AC-FHKNPRTV-Y]{4}$\"\n",
        "                  #\"^[ACDEFHKNPRTVWXY]{1}[0-9]{1}[0-9W]{1}[\\ \\-]?[0-9ACDEFHKNPRTVWXY]{4}$\"\n",
        "  #print(x)\n",
        "  if x:\n",
        "    print(\"Eircode = \" + eircode)\n",
        "    #routing_key = re.split(\"[\\ \\-]?[0-9ACDEFHKNPRTVWXY]{4}$\", eircode)\n",
        "    #unique_identifier = re.split(\"^[ACDEFHKNPRTVWXY]{1}[0-9]{2}[\\ \\-]?\", eircode)\n",
        "    print(\"Valid Eircode, Routing Key=\" + eircode[0:3] + \", Unique Identifier= \" + eircode[3:7])\n",
        "    for i in KeyRouteList:\n",
        "      if eircode[0:3] in i:\n",
        "        print(\"Desination = \" + i[1])\n",
        "  else:\n",
        "    print(\"Eircode = \" + eircode)\n",
        "    print(\"Invalid Eircode\")\n",
        "\n",
        "eircodeValidator(\"V94T9PX\")\n",
        "eircodeValidator(\"v94T9PX\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-17 21:14:19--  https://gist.githubusercontent.com/ajoorabchi/eac194a79dd26de8864f9206b7842ff1/raw/8ea1d8d5f74b5b2724e378b43d4df6094990c7db/Eircode%2520Routing%2520Key%2520Boundaries.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1934 (1.9K) [text/plain]\n",
            "Saving to: ‘Eircode Routing Key Boundaries.csv.61’\n",
            "\n",
            "\r          Eircode R   0%[                    ]       0  --.-KB/s               \rEircode Routing Key 100%[===================>]   1.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-17 21:14:19 (35.4 MB/s) - ‘Eircode Routing Key Boundaries.csv.61’ saved [1934/1934]\n",
            "\n",
            "[('ROUTING KEY', 'DESCRIPTOR'), ('A41', 'BALLYBOUGHAL'), ('A42', 'GARRISTOWN'), ('A45', 'OLDTOWN'), ('A63', 'GREYSTONES'), ('A67', 'WICKLOW'), ('A75', 'CASTLEBLAYNEY'), ('A81', 'CARRICKMACROSS'), ('A82', 'KELLS'), ('A83', 'ENFIELD'), ('A84', 'ASHBOURNE'), ('A85', 'DUNSHAUGHLIN'), ('A86', 'DUNBOYNE'), ('A91', 'DUNDALK'), ('A92', 'DROGHEDA'), ('A94', 'BLACKROCK'), ('A96', 'GLENAGEARY'), ('A98', 'BRAY'), ('C15', 'NAVAN'), ('D01', 'DUBLIN 1'), ('D02', 'DUBLIN 2'), ('D03', 'DUBLIN 3'), ('D04', 'DUBLIN 4'), ('D05', 'DUBLIN 5'), ('D06', 'DUBLIN 6'), ('D07', 'DUBLIN 7'), ('D08', 'DUBLIN 8'), ('D09', 'DUBLIN 9'), ('D10', 'DUBLIN 10'), ('D11', 'DUBLIN 11'), ('D12', 'DUBLIN 12'), ('D13', 'DUBLIN 13'), ('D14', 'DUBLIN 14'), ('D15', 'DUBLIN 15'), ('D16', 'DUBLIN 16'), ('D17', 'DUBLIN 17'), ('D18', 'DUBLIN 18'), ('D20', 'DUBLIN 20'), ('D22', 'DUBLIN 22'), ('D24', 'DUBLIN 24'), ('D6W', 'DUBLIN 6W'), ('E21', 'CAHIR'), ('E25', 'CASHEL'), ('E32', 'CARRICK-ON-SUIR'), ('E34', 'TIPPERARY'), ('E41', 'THURLES'), ('E45', 'NENAGH'), ('E53', 'ROSCREA'), ('E91', 'CLONMEL'), ('F12', 'CLAREMORRIS'), ('F23', 'CASTLEBAR'), ('F26', 'BALLINA'), ('F28', 'WESTPORT'), ('F31', 'BALLINROBE'), ('F35', 'BALLYHAUNIS'), ('F42', 'ROSCOMMON'), ('F45', 'CASTLEREA'), ('F52', 'BOYLE'), ('F56', 'BALLYMOTE'), ('F91', 'SLIGO'), ('F92', 'LETTERKENNY'), ('F93', 'LIFFORD'), ('F94', 'DONEGAL'), ('H12', 'CAVAN'), ('H14', 'BELTURBET'), ('H16', 'COOTEHILL'), ('H18', 'MONAGHAN'), ('H23', 'CLONES'), ('H53', 'BALLINASLOE'), ('H54', 'TUAM'), ('H62', 'LOUGHREA'), ('H65', 'ATHENRY'), ('H71', 'CLIFDEN'), ('H91', 'GALWAY'), ('K32', 'BALBRIGGAN'), ('K34', 'SKERRIES'), ('K36', 'MALAHIDE'), ('K45', 'LUSK'), ('K56', 'RUSH'), ('K67', 'SWORDS'), ('K78', 'LUCAN'), ('N37', 'ATHLONE'), ('N39', 'LONGFORD'), ('N41', 'CARRICK-ON-SHANNON'), ('N91', 'MULLINGAR'), ('P12', 'MACROOM'), ('P14', 'CORK - CROOKSTOWN'), ('P17', 'KINSALE'), ('P24', 'COBH'), ('P25', 'MIDLETON'), ('P31', 'BALLINCOLLIG'), ('P32', 'CORK - DONOUGHMORE'), ('P36', 'YOUGHAL'), ('P43', 'CARRIGALINE'), ('P47', 'CORK - DUNMANWAY'), ('P51', 'MALLOW'), ('P56', 'CHARLEVILLE'), ('P61', 'FERMOY'), ('P67', 'MITCHELSTOWN'), ('P72', 'BANDON'), ('P75', 'BANTRY'), ('P81', 'SKIBBEREEN'), ('P85', 'CLONAKILTY'), ('R14', 'ATHY'), ('R21', 'MUINE BHEAG'), ('R32', 'PORTLAOISE'), ('R35', 'TULLAMORE'), ('R42', 'BIRR'), ('R45', 'EDENDERRY'), ('R51', 'KILDARE'), ('R56', 'CURRAGH CAMP'), ('R93', 'CARLOW'), ('R95', 'KILKENNY'), ('T12', 'CORK - BALLINHASSIG'), ('T23', 'CORK - BLARNEY'), ('T34', 'CORK - WHITECHURCH'), ('T45', 'LITTLE ISLAND'), ('T56', 'CORK - WATERGRASSHILL'), ('V14', 'SHANNON'), ('V15', 'KILRUSH'), ('V23', 'CAHERCIVEEN'), ('V31', 'LISTOWEL'), ('V35', 'KILMALLOCK'), ('V42', 'NEWCASTLE WEST'), ('V92', 'TRALEE'), ('V93', 'KILLARNEY'), ('V94', 'LIMERICK'), ('V95', 'ENNIS'), ('W12', 'NEWBRIDGE'), ('W23', 'MAYNOOTH'), ('W34', 'MONASTEREVIN'), ('W91', 'NAAS'), ('X35', 'DUNGARVAN'), ('X42', 'KILMACTHOMAS'), ('X91', 'WATERFORD'), ('Y14', 'ARKLOW'), ('Y21', 'ENNISCORTHY'), ('Y25', 'GOREY'), ('Y34', 'NEW ROSS'), ('Y35', 'WEXFORD')]\n",
            "Eircode = V94T9PX\n",
            "Valid Eircode, Routing Key=V94, Unique Identifier= T9PX\n",
            "Desination = LIMERICK\n",
            "Eircode = v94T9PX\n",
            "Invalid Eircode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgVRQLVKY0sC"
      },
      "source": [
        "Task 2:\n",
        "1. Download the 'Complete Works of William Shakespeare' from here\n",
        "2. Read in the content of the file and print its first 50 lines.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8DfFRnAZv6Q",
        "outputId": "99dbda97-5468-43ad-b76e-e25d1f6079cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!wget https://www.gutenberg.org/files/100/100-0.txt\n",
        "filePath = \"/content/100-0.txt\"\n",
        "\n",
        "ShakespeareFile = open(filePath, \"r\")\n",
        "ShakespeareContent = ShakespeareFile.read()\n",
        "ShakespeareContent = ShakespeareContent.splitlines()\n",
        "print(ShakespeareContent[0:50])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-17 23:04:32--  https://www.gutenberg.org/files/100/100-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5767184 (5.5M) [text/plain]\n",
            "Saving to: ‘100-0.txt’\n",
            "\n",
            "100-0.txt           100%[===================>]   5.50M  5.57MB/s    in 1.0s    \n",
            "\n",
            "2020-10-17 23:04:33 (5.57 MB/s) - ‘100-0.txt’ saved [5767184/5767184]\n",
            "\n",
            "['\\ufeffProject Gutenberg’s The Complete Works of William Shakespeare, by William Shakespeare', '', 'This eBook is for the use of anyone anywhere in the United States and', 'most other parts of the world at no cost and with almost no restrictions', 'whatsoever.  You may copy it, give it away or re-use it under the terms', 'of the Project Gutenberg License included with this eBook or online at', 'www.gutenberg.org.  If you are not located in the United States, you’ll', 'have to check the laws of the country where you are located before using', 'this ebook.', '', '', 'Title: The Complete Works of William Shakespeare', '', 'Author: William Shakespeare', '', 'Release Date: January 1994 [EBook #100]', 'Last Updated: August 6, 2020', '', 'Language: English', '', 'Character set encoding: UTF-8', '', '*** START OF THIS PROJECT GUTENBERG EBOOK THE COMPLETE WORKS OF WILLIAM SHAKESPEARE ***', '', '', '', '', 'The Complete Works of William Shakespeare', '', '', '', 'by William Shakespeare', '', '', '', '', '      Contents', '', '', '', '               THE SONNETS', '', '               ALL’S WELL THAT ENDS WELL', '', '               THE TRAGEDY OF ANTONY AND CLEOPATRA', '', '               AS YOU LIKE IT', '', '               THE COMEDY OF ERRORS', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NIjle5vZwSj"
      },
      "source": [
        "3. Use the tf.keras.preprocessing.text.Tokenizer class to:\n",
        "Tokenize the Shakespeare corpus\n",
        "\n",
        "    (a) Print out the total number of  Tokens in the corpus\n",
        "\n",
        "    (b) print out the total number of Types in the corpus\n",
        "    \n",
        "    (c) Print out the most frequent Type in corpus and its frequency\n",
        "\n",
        "[3 marks]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gckGg1uYb-0k",
        "outputId": "e56f5a58-f77c-492f-be21-1b8a68d5f158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "\n",
        "num_words = 1000\n",
        "oov_token = '<UNK>'\n",
        "pad_type = 'post'\n",
        "trunc_type = 'post'\n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(ShakespeareContent)\n",
        "train_sequences = tokenizer.texts_to_sequences(ShakespeareContent)\n",
        "word_index = tokenizer.word_index\n",
        "maxlen = max([len(x) for x in train_sequences])\n",
        "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
        "\n",
        "print(\"Word index:\\n\", word_index)\n",
        "print(\"\\nTraining sequences:\\n\", train_sequences)\n",
        "print(\"\\nPadded training sequences:\\n\", train_padded)\n",
        "print(\"\\nPadded training shape:\", train_padded.shape)\n",
        "print(\"Training sequences data type:\", type(train_sequences))\n",
        "print(\"Padded Training sequences data type:\", type(train_padded))\n",
        "\n",
        "\n",
        "\n",
        "#Tokenizer.fit_on_texts(ShakespeareContent['text'].values)\n",
        "#sequences = Tokenizer.texts_to_sequences(df['text'].values)\n",
        "#word_index = Tokenizer.word_index\n",
        "#print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcDbyXxfD7Pz"
      },
      "source": [
        "#Testing VS Code\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "\n",
        "filePath = \"Text Analytics and NLP/etivity1/100-0.txt\"\n",
        "\n",
        "ShakespeareFile = open(filePath, encoding='utf-8')\n",
        "ShakespeareContent = ShakespeareFile.read()\n",
        "ShakespeareContent = ShakespeareContent.splitlines()\n",
        "print(ShakespeareContent[0:50])\n",
        "\n",
        "#Get total number of words and unique words\n",
        "n_words = len(ShakespeareContent) #169442\n",
        "unique_words = len(set(ShakespeareContent)) #120049\n",
        "\n",
        "# define the text\n",
        "# tokenizing the text\n",
        "# sample_text = 'This is a sample sentence.'\n",
        "# tokens = text_to_word_sequence(sample_text)\n",
        "# print(tokens)\n",
        "\n",
        "num_words = 120049\n",
        "oov_token = '<UNK>'\n",
        "pad_type = 'post'\n",
        "trunc_type = 'post'\n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(ShakespeareContent)\n",
        "train_sequences = tokenizer.texts_to_sequences(ShakespeareContent)\n",
        "word_index = tokenizer.word_index\n",
        "maxlen = max([len(x) for x in train_sequences])\n",
        "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
        "\n",
        "print(\"Word index:\\n\", word_index)\n",
        "print(\"\\nTraining sequences:\\n\", train_sequences)\n",
        "print(\"\\nPadded training sequences:\\n\", train_padded)\n",
        "print(\"\\nPadded training shape:\", train_padded.shape)\n",
        "print(\"Training sequences data type:\", type(train_sequences))\n",
        "print(\"Padded Training sequences data type:\", type(train_padded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5vyNF15auWp"
      },
      "source": [
        "4. Use the PorterStemmer in the NLTK package to: \n",
        "\n",
        "    (a) stem all the Types in the Shakespeare corpus\n",
        "\n",
        "    (b) print out the total number of Types in the corpus after stemming (you should see ~30% reduction after stemming)\n",
        "\n",
        "[2 marks]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmv8gAQSa-dv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NMwNUf4a-0H"
      },
      "source": [
        "5. Use the Sentence Segmentation module in the spaCy package to: \n",
        "\n",
        "      (a) Segment sentences in the last 100 lines of the Shakespeare corpus\n",
        "\n",
        "      (b) print out the sentences and their total number\n",
        "\n",
        "[2 marks]\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4HLWvidb_bK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}